{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering sites to make future API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API endpoint to retrieve all Stack Exchange sites\n",
    "sites_url = \"https://api.stackexchange.com/2.3/sites\"\n",
    "\n",
    "# Load API keys\n",
    "with open('request-keys.json', 'r') as key_file:\n",
    "    keys = json.load(key_file)\n",
    "\n",
    "# Retrieve the list of Stack Exchange sites\n",
    "params = {\n",
    "    \"pagesize\": 1000,  # Fetch up to 500 sites at once\n",
    "    \"key\": keys['key'],\n",
    "    \"client_id\": keys['client_id']\n",
    "}\n",
    "\n",
    "response = requests.get(sites_url, params=params)\n",
    "sites_data = response.json()\n",
    "\n",
    "# Extract the 'api_site_parameter' values (Those are needed to access the sites through the API)\n",
    "matches = [\n",
    "    site['api_site_parameter']\n",
    "    for site in sites_data['items']\n",
    "    if 'meta' not in site['api_site_parameter']\n",
    "]\n",
    "\n",
    "with open('communities.txt', 'w') as f:\n",
    "    for match in matches:\n",
    "        f.write(f\"{match}\\n\")\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Number of days to look back\n",
    "number_of_days = 7\n",
    "\n",
    "# API endpoints\n",
    "url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "answers_url = \"https://api.stackexchange.com/2.3/questions/{ids}/answers\"\n",
    "\n",
    "# Calculate the 'fromdate' parameter in Unix time\n",
    "fromdate = int(time.time()) - number_of_days * 24 * 60 * 60\n",
    "\n",
    "# Load API keys and client ids\n",
    "with open('request-keys.json', 'r') as key_file:\n",
    "    keys = json.load(key_file)\n",
    "\n",
    "page = 1  # Start from the first page\n",
    "\n",
    "# Load sites from communities.txt\n",
    "with open('communities.txt', 'r') as f:\n",
    "    sites = [line.strip() for line in f.readlines()]\n",
    "\n",
    "for site in sites:\n",
    "    print(site)\n",
    "    has_more = True\n",
    "\n",
    "    # Loop to paginate through the results\n",
    "    while has_more:\n",
    "        try:\n",
    "            # Set parameters for the request\n",
    "            params = {\n",
    "                \"order\": \"desc\",\n",
    "                \"sort\": \"creation\",\n",
    "                \"pagesize\": 100,\n",
    "                \"page\": page,  # Set the current page number\n",
    "                \"site\": site,\n",
    "                \"key\": keys['key'],\n",
    "                \"client_id\": keys['client_id'],\n",
    "                \"filter\": \"withbody\",\n",
    "                \"redirect_uri\": \"https://stackexchange.com/oauth/login_success\"\n",
    "            }\n",
    "\n",
    "            # Make the API request\n",
    "            response = requests.get(url, params=params)\n",
    "            data = response.json()\n",
    "\n",
    "            # Process the items and retrieve asnwers (if needed)\n",
    "            for question in data['items']:\n",
    "                filtered_question = {\n",
    "                    \"tags\": question.get(\"tags\"),\n",
    "                    \"reputation\": question['owner'].get(\"reputation\"),\n",
    "                    \"is_answered\": question.get(\"is_answered\"),\n",
    "                    \"score\": question.get(\"score\"),\n",
    "                    \"last_activity_date\": question.get(\"last_activity_date\"),\n",
    "                    \"question_id\": question.get(\"question_id\"),\n",
    "                    \"title\": question.get(\"title\"),\n",
    "                    \"body\": question.get(\"body\")\n",
    "                }\n",
    "\n",
    "                question_id = question['question_id']\n",
    "\n",
    "                # Make a request to get answers\n",
    "                answer_response = requests.get(answers_url.format(ids=question_id), params={\n",
    "                    \"order\": \"desc\",\n",
    "                    \"sort\": \"creation\",\n",
    "                    \"site\": \"linux\",\n",
    "                    \"key\": keys['key'],\n",
    "                    \"client_id\": keys['client_id'],\n",
    "                    \"filter\": \"withbody\"\n",
    "                })\n",
    "\n",
    "                with open(f'stackexchange_data.json', 'a') as f: # dump questions into the json file\n",
    "                    json.dump(filtered_question, f)\n",
    "                    f.write(',\\n')\n",
    "\n",
    "                for answer in answer_response.json()['items']:\n",
    "                    filtered_answer = {\n",
    "                    \"reputation\": question['owner'].get(\"reputation\"),\n",
    "                    \"is_accepted\": question.get(\"is_accepted\"),\n",
    "                    \"score\": question.get(\"score\"),\n",
    "                    \"last_activity_date\": question.get(\"last_activity_date\"),\n",
    "                    \"question_id\": question.get(\"question_id\"),\n",
    "                    \"answer_id\": answer.get(\"answer_id\"),\n",
    "                    \"title\": question.get(\"title\"),\n",
    "                    \"body\": question.get(\"body\")\n",
    "                    }\n",
    "                    with open(f'stackexchange_data.json', 'a') as f: # dump answers into the json file\n",
    "                        json.dump(filtered_answer, f)\n",
    "                        f.write(',\\n')\n",
    "\n",
    "            # Continue looping if 'has_more' is True\n",
    "            if data['items'][-1]['creation_date'] < fromdate: # Ensuring that only messages newer than specified will be retrieved\n",
    "                has_more = False\n",
    "\n",
    "            # Increment the page number for the next batch\n",
    "            page += 1\n",
    "\n",
    "            # Sleep between requests to avoid hitting the rate limit\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "institut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
